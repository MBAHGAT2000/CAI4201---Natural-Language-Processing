{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f77200cf",
   "metadata": {},
   "source": [
    "# <h1 align=center>**Text Classification**</h1>\n",
    "Text classification is the process of categorizing text into organized groups. It can be applied to words, sentences, or entire documents. The goal is to automatically understand the content of the text and sort it into the correct category based on its meaning or context."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe08134-68d5-49a5-97ba-b11ec84be674",
   "metadata": {},
   "source": [
    "- <a href='#Reading Data'>Reading Data</a>\n",
    "- <a href='#handle dataset'>handle dataset</a>\n",
    "- <a href='#Text Cleaning'>Text Cleaning</a>\n",
    "- <a href='#TF-IDF Vecorization'>TF-IDF Vecorization</a>\n",
    "- <a href='#Feature Creation'>Feature Creation</a>\n",
    "- <a href='#ML Classifiers'>ML Classifiers</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbbfcf6-4eb8-4956-a701-77407d126a31",
   "metadata": {},
   "source": [
    "<b>\n",
    "<a id='Reading Data'></a>\n",
    "<font size=\"5\">Reading Data</font>\n",
    "</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f9cad60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  \\\n",
       "0   ham   \n",
       "1   ham   \n",
       "2  spam   \n",
       "3   ham   \n",
       "4   ham   \n",
       "\n",
       "                                                                                                  text  \n",
       "0  Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...  \n",
       "1                                                                        Ok lar... Joking wif u oni...  \n",
       "2  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...  \n",
       "3                                                    U dun say so early hor... U c already then say...  \n",
       "4                                        Nah I don't think he goes to usf, he lives around here though  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# to increasing col width\n",
    "pd.set_option('display.max_colwidth',100)\n",
    "dataset = pd.read_csv('spam.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f1caa3-c048-4319-b093-18477889ac78",
   "metadata": {},
   "source": [
    "<b>\n",
    "<a id='handle dataset'></a>\n",
    "<font size=\"5\">handle dataset</font>\n",
    "</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2783021d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  \\\n",
       "0      0   \n",
       "1      0   \n",
       "2      1   \n",
       "3      0   \n",
       "4      0   \n",
       "\n",
       "                                                                                                  text  \n",
       "0  Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...  \n",
       "1                                                                        Ok lar... Joking wif u oni...  \n",
       "2  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...  \n",
       "3                                                    U dun say so early hor... U c already then say...  \n",
       "4                                        Nah I don't think he goes to usf, he lives around here though  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['label'] = dataset['label'].replace({'ham': 0, 'spam': 1})\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953d38a2",
   "metadata": {},
   "source": [
    "### NLP PIPELINE \n",
    "#### Row Text -> Tokenization -> Text Cleaning -> Vectorization -> ML Algorithm -> classifiying text\n",
    "\n",
    "#### Preprocessing = Tokenization and Text Cleaning\n",
    "#### vectorization = Convert text to numbers\n",
    "#### vectorization methods (word2vec - BOW - TFIDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256ca9d5",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703b8c8b",
   "metadata": {},
   "source": [
    "#### Preprocessing (Removing Punctuation - Tokenization - Remove Stop Words - stemming/lemmatizing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2135129",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965112e8",
   "metadata": {},
   "source": [
    "### lemmatization is more accurate but computationally expensive\n",
    "### lemmatization reduces to a dictionary word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52a3ece",
   "metadata": {},
   "source": [
    "# Vectorization\n",
    "##### Vectorization : process of encoding text as integers to create feature vecors\n",
    "##### Feature vector : vector of numerical features that represent an object\n",
    "##### Types Of Vecorization (count vectorization - Ngrams - TFIDF)\n",
    "count vectorization  == count unique words occure in the sms how many times!! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e2f552",
   "metadata": {},
   "source": [
    "<b>\n",
    "<a id='Text Cleaning'></a>\n",
    "<font size=\"5\">Text Cleaning</font>\n",
    "</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d31d8a",
   "metadata": {},
   "source": [
    "###### apply on our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1c0f4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk import word_tokenize\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "#wn = nltk.WordNetLemmatizer()\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "def clean_text(txt):\n",
    "    txt_nopunct = \"\".join([c for c in txt if c not in string.punctuation ])\n",
    "    tokens = word_tokenize(txt_nopunct)\n",
    "    txt_clean = [word for word in tokens if word not in stopwords]\n",
    "    tokens_stem = [ps.stem(word) for word in txt_clean]\n",
    "    #tokens_lemma = [wn.lemmatize(word) for word in txt_clean]\n",
    "    return tokens_stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "665b57d3-40e1-47a0-9c79-2f68b68887c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...</td>\n",
       "      <td>[go, jurong, point, crazi, avail, bugi, n, great, world, la, e, buffet, cine, got, amor, wat]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>[ok, lar, joke, wif, u, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...</td>\n",
       "      <td>[free, entri, 2, wkli, comp, win, fa, cup, final, tkt, 21st, may, 2005, text, fa, 87121, receiv,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>[u, dun, say, earli, hor, u, c, alreadi, say]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
       "      <td>[nah, i, dont, think, goe, usf, live, around, though]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  \\\n",
       "0      0   \n",
       "1      0   \n",
       "2      1   \n",
       "3      0   \n",
       "4      0   \n",
       "\n",
       "                                                                                                  text  \\\n",
       "0  Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...   \n",
       "1                                                                        Ok lar... Joking wif u oni...   \n",
       "2  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...   \n",
       "3                                                    U dun say so early hor... U c already then say...   \n",
       "4                                        Nah I don't think he goes to usf, he lives around here though   \n",
       "\n",
       "                                                                                            text_clean  \n",
       "0        [go, jurong, point, crazi, avail, bugi, n, great, world, la, e, buffet, cine, got, amor, wat]  \n",
       "1                                                                         [ok, lar, joke, wif, u, oni]  \n",
       "2  [free, entri, 2, wkli, comp, win, fa, cup, final, tkt, 21st, may, 2005, text, fa, 87121, receiv,...  \n",
       "3                                                        [u, dun, say, earli, hor, u, c, alreadi, say]  \n",
       "4                                                [nah, i, dont, think, goe, usf, live, around, though]  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"text_clean\"] = dataset[\"text\"].apply(clean_text)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6420e777-5d32-43e2-b98e-905dcb1fba18",
   "metadata": {},
   "source": [
    "<b>\n",
    "<a id='TF-IDF Vecorization'></a>\n",
    "<font size=\"5\">TF-IDF Vecorization</font>\n",
    "</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f081c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572, 8176)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# cv1 = CountVectorizer(analyzer=clean_text()) if i want to perform cleaning before it\n",
    "tfidf_vec = TfidfVectorizer(analyzer=clean_text)\n",
    "tfidf_vec_fit = tfidf_vec.fit(dataset['text'])\n",
    "X_tfidf = tfidf_vec.fit_transform(dataset['text'])\n",
    "print(X_tfidf.shape)\n",
    "#df = pd.DataFrame(X_tfidf.toarray(),columns=tfidf_vec.get_feature_names_out())\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415a83ab",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "- creating new features of transforming existing features using domain knowledge of the data, that make machine learning \n",
    "algorithm work better\n",
    "- creating features\n",
    "    - length of documents\n",
    "    - average word size within a document\n",
    "    - use of punctuation in the text\n",
    "    - capitalization of words in a document\n",
    "    - ...\n",
    "    - ...\n",
    "    - ...\n",
    "- Transformations( applying some transformations to data can make it work better )\n",
    "    - Power transformations (x^2 , √x ,etc )   #√ = alt251\n",
    "    - Standardizing data\n",
    "    - Normalization : bring different features to similar scale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa9a85d",
   "metadata": {},
   "source": [
    "<b>\n",
    "<a id='Feature Creation'></a>\n",
    "<font size=\"5\">Feature Creation</font>\n",
    "</b>\n",
    "\n",
    " message length - punctuation usage - stop word usage - capitalization usage - average word length usage ...."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61ec34e",
   "metadata": {},
   "source": [
    "###### message length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f242ff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>text_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...</td>\n",
       "      <td>[go, jurong, point, crazi, avail, bugi, n, great, world, la, e, buffet, cine, got, amor, wat]</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>[ok, lar, joke, wif, u, oni]</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...</td>\n",
       "      <td>[free, entri, 2, wkli, comp, win, fa, cup, final, tkt, 21st, may, 2005, text, fa, 87121, receiv,...</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>[u, dun, say, earli, hor, u, c, alreadi, say]</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
       "      <td>[nah, i, dont, think, goe, usf, live, around, though]</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  \\\n",
       "0      0   \n",
       "1      0   \n",
       "2      1   \n",
       "3      0   \n",
       "4      0   \n",
       "\n",
       "                                                                                                  text  \\\n",
       "0  Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...   \n",
       "1                                                                        Ok lar... Joking wif u oni...   \n",
       "2  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...   \n",
       "3                                                    U dun say so early hor... U c already then say...   \n",
       "4                                        Nah I don't think he goes to usf, he lives around here though   \n",
       "\n",
       "                                                                                            text_clean  \\\n",
       "0        [go, jurong, point, crazi, avail, bugi, n, great, world, la, e, buffet, cine, got, amor, wat]   \n",
       "1                                                                         [ok, lar, joke, wif, u, oni]   \n",
       "2  [free, entri, 2, wkli, comp, win, fa, cup, final, tkt, 21st, may, 2005, text, fa, 87121, receiv,...   \n",
       "3                                                        [u, dun, say, earli, hor, u, c, alreadi, say]   \n",
       "4                                                [nah, i, dont, think, goe, usf, live, around, though]   \n",
       "\n",
       "   text_len  \n",
       "0       111  \n",
       "1        29  \n",
       "2       155  \n",
       "3        49  \n",
       "4        61  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['text_len'] = dataset['text'].apply(lambda x: len(x))\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c313f2f",
   "metadata": {},
   "source": [
    "###### punctuation length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6b8e8137",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "def punctuation_count(txt):\n",
    "    count= sum([1 for c in txt if c in string.punctuation])\n",
    "    return (count / len(txt)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "160d5351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>text_len</th>\n",
       "      <th>punctuation_%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...</td>\n",
       "      <td>[go, jurong, point, crazi, avail, bugi, n, great, world, la, e, buffet, cine, got, amor, wat]</td>\n",
       "      <td>111</td>\n",
       "      <td>8.108108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>[ok, lar, joke, wif, u, oni]</td>\n",
       "      <td>29</td>\n",
       "      <td>20.689655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...</td>\n",
       "      <td>[free, entri, 2, wkli, comp, win, fa, cup, final, tkt, 21st, may, 2005, text, fa, 87121, receiv,...</td>\n",
       "      <td>155</td>\n",
       "      <td>3.870968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>[u, dun, say, earli, hor, u, c, alreadi, say]</td>\n",
       "      <td>49</td>\n",
       "      <td>12.244898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
       "      <td>[nah, i, dont, think, goe, usf, live, around, though]</td>\n",
       "      <td>61</td>\n",
       "      <td>3.278689</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  \\\n",
       "0      0   \n",
       "1      0   \n",
       "2      1   \n",
       "3      0   \n",
       "4      0   \n",
       "\n",
       "                                                                                                  text  \\\n",
       "0  Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...   \n",
       "1                                                                        Ok lar... Joking wif u oni...   \n",
       "2  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...   \n",
       "3                                                    U dun say so early hor... U c already then say...   \n",
       "4                                        Nah I don't think he goes to usf, he lives around here though   \n",
       "\n",
       "                                                                                            text_clean  \\\n",
       "0        [go, jurong, point, crazi, avail, bugi, n, great, world, la, e, buffet, cine, got, amor, wat]   \n",
       "1                                                                         [ok, lar, joke, wif, u, oni]   \n",
       "2  [free, entri, 2, wkli, comp, win, fa, cup, final, tkt, 21st, may, 2005, text, fa, 87121, receiv,...   \n",
       "3                                                        [u, dun, say, earli, hor, u, c, alreadi, say]   \n",
       "4                                                [nah, i, dont, think, goe, usf, live, around, though]   \n",
       "\n",
       "   text_len  punctuation_%  \n",
       "0       111       8.108108  \n",
       "1        29      20.689655  \n",
       "2       155       3.870968  \n",
       "3        49      12.244898  \n",
       "4        61       3.278689  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['punctuation_%'] = dataset['text'].apply(lambda x: punctuation_count(x))\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a39c51",
   "metadata": {},
   "source": [
    "<b>\n",
    "<a id='ML Classifiers'></a>\n",
    "<font size=\"5\">ML Classifiers</font>\n",
    "</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "07e67e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score,confusion_matrix,classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2065e543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>text_len</th>\n",
       "      <th>punctuation_%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...</td>\n",
       "      <td>[go, jurong, point, crazi, avail, bugi, n, great, world, la, e, buffet, cine, got, amor, wat]</td>\n",
       "      <td>111</td>\n",
       "      <td>8.108108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>[ok, lar, joke, wif, u, oni]</td>\n",
       "      <td>29</td>\n",
       "      <td>20.689655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...</td>\n",
       "      <td>[free, entri, 2, wkli, comp, win, fa, cup, final, tkt, 21st, may, 2005, text, fa, 87121, receiv,...</td>\n",
       "      <td>155</td>\n",
       "      <td>3.870968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>[u, dun, say, earli, hor, u, c, alreadi, say]</td>\n",
       "      <td>49</td>\n",
       "      <td>12.244898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
       "      <td>[nah, i, dont, think, goe, usf, live, around, though]</td>\n",
       "      <td>61</td>\n",
       "      <td>3.278689</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  \\\n",
       "0      0   \n",
       "1      0   \n",
       "2      1   \n",
       "3      0   \n",
       "4      0   \n",
       "\n",
       "                                                                                                  text  \\\n",
       "0  Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...   \n",
       "1                                                                        Ok lar... Joking wif u oni...   \n",
       "2  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...   \n",
       "3                                                    U dun say so early hor... U c already then say...   \n",
       "4                                        Nah I don't think he goes to usf, he lives around here though   \n",
       "\n",
       "                                                                                            text_clean  \\\n",
       "0        [go, jurong, point, crazi, avail, bugi, n, great, world, la, e, buffet, cine, got, amor, wat]   \n",
       "1                                                                         [ok, lar, joke, wif, u, oni]   \n",
       "2  [free, entri, 2, wkli, comp, win, fa, cup, final, tkt, 21st, may, 2005, text, fa, 87121, receiv,...   \n",
       "3                                                        [u, dun, say, earli, hor, u, c, alreadi, say]   \n",
       "4                                                [nah, i, dont, think, goe, usf, live, around, though]   \n",
       "\n",
       "   text_len  punctuation_%  \n",
       "0       111       8.108108  \n",
       "1        29      20.689655  \n",
       "2       155       3.870968  \n",
       "3        49      12.244898  \n",
       "4        61       3.278689  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dataset['hate'] = dataset['label'].map( {'off': 1, 'notOff': 0} ).astype(int)\n",
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2eeb978c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_tfidf_train, data_tfidf_test, label_train, label_test = train_test_split(X_tfidf, dataset[\"label\"], test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df939a8c",
   "metadata": {},
   "source": [
    "# 1-Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c59e0dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 1.0 / Recall: 0.653 / Accuracy: 0.955\n",
      "[[1453    0]\n",
      " [  76  143]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      1453\n",
      "           1       1.00      0.65      0.79       219\n",
      "\n",
      "    accuracy                           0.95      1672\n",
      "   macro avg       0.98      0.83      0.88      1672\n",
      "weighted avg       0.96      0.95      0.95      1672\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spam_detect_model = MultinomialNB().fit(data_tfidf_train, label_train)\n",
    "pred_test_MNB = spam_detect_model.predict(data_tfidf_test)\n",
    "precision = precision_score(label_test, pred_test_MNB)\n",
    "recall = recall_score(label_test, pred_test_MNB)\n",
    "accuracy = accuracy_score(label_test, pred_test_MNB)\n",
    "print('Precision: {} / Recall: {} / Accuracy: {}'.format(round(precision, 3), round(recall, 3), round(accuracy, 3)))\n",
    "print(confusion_matrix(label_test,pred_test_MNB))\n",
    "print (classification_report(label_test, pred_test_MNB))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21f0bd2",
   "metadata": {},
   "source": [
    "# 2-Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3b972bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.832 / Recall: 0.813 / Accuracy: 0.954\n",
      "[[1417   36]\n",
      " [  41  178]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97      1453\n",
      "           1       0.83      0.81      0.82       219\n",
      "\n",
      "    accuracy                           0.95      1672\n",
      "   macro avg       0.90      0.89      0.90      1672\n",
      "weighted avg       0.95      0.95      0.95      1672\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spam_detect_model = tree.DecisionTreeClassifier().fit(data_tfidf_train, label_train)\n",
    "pred_test_MNB = spam_detect_model.predict(data_tfidf_test)\n",
    "precision = precision_score(label_test, pred_test_MNB)\n",
    "recall = recall_score(label_test, pred_test_MNB)\n",
    "accuracy = accuracy_score(label_test, pred_test_MNB)\n",
    "print('Precision: {} / Recall: {} / Accuracy: {}'.format(round(precision, 3), round(recall, 3), round(accuracy, 3)))\n",
    "print(confusion_matrix(label_test,pred_test_MNB))\n",
    "print (classification_report(label_test, pred_test_MNB))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0744ce40",
   "metadata": {},
   "source": [
    "# 3- Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "baae307b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 1.0 / Recall: 0.799 / Accuracy: 0.974\n",
      "[[1453    0]\n",
      " [  44  175]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99      1453\n",
      "           1       1.00      0.80      0.89       219\n",
      "\n",
      "    accuracy                           0.97      1672\n",
      "   macro avg       0.99      0.90      0.94      1672\n",
      "weighted avg       0.97      0.97      0.97      1672\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spam_detect_model = RandomForestClassifier().fit(data_tfidf_train, label_train)\n",
    "pred_test_MNB = spam_detect_model.predict(data_tfidf_test)\n",
    "precision = precision_score(label_test, pred_test_MNB)\n",
    "recall = recall_score(label_test, pred_test_MNB)\n",
    "accuracy = accuracy_score(label_test, pred_test_MNB)\n",
    "print('Precision: {} / Recall: {} / Accuracy: {}'.format(round(precision, 3), round(recall, 3), round(accuracy, 3)))\n",
    "print(confusion_matrix(label_test,pred_test_MNB))\n",
    "print (classification_report(label_test, pred_test_MNB))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc44b015",
   "metadata": {},
   "source": [
    "# test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "894ec781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham\n"
     ]
    }
   ],
   "source": [
    "text = 'Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...'\n",
    "X = tfidf_vec_fit.transform([text])\n",
    "pred = spam_detect_model.predict(X)\n",
    "if pred[0]==0:\n",
    "    print('ham')\n",
    "else:\n",
    "    print('spam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1b26e1b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "spam\n"
     ]
    }
   ],
   "source": [
    "text = 'SIX chances to win CASH! From 100 to 20,000 pounds txt> CSH11 and send to 87575. Cost 150p/day, 6days, 16+ TsandCs apply Reply HL 4 info'\n",
    "X = tfidf_vec_fit.transform([text])\n",
    "pred = spam_detect_model.predict(X)\n",
    "print(pred)\n",
    "if pred[0]==0:\n",
    "    print('ham')\n",
    "else:\n",
    "    print('spam')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58f8c6a",
   "metadata": {},
   "source": [
    "# Save Model Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5c265277",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('tfidf_vec_fit.pickle', 'wb') as handle:\n",
    "    pickle.dump(tfidf_vec_fit,handle)\n",
    "\n",
    "# save the model to disk\n",
    "filename = 'RandomForest.sav'\n",
    "pickle.dump(spam_detect_model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a468eb",
   "metadata": {},
   "source": [
    "# load Model Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "77774b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tfidf_vec_fit.pickle', 'rb') as handle:\n",
    "    tfidf_vec_fit_loaded = pickle.load(handle)\n",
    "    \n",
    "with open('RandomForest.sav', 'rb') as handle:\n",
    "    spam_detect_model_loaded = pickle.load(handle)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c544f3",
   "metadata": {},
   "source": [
    "# predict from loaded model component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "312c78cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam\n"
     ]
    }
   ],
   "source": [
    "text = 'Please call our customer service representative on FREEPHONE 0808 145 4742 between 9am-11pm as you have WON a guaranteed Ã¥Â£1000 cash or Ã¥Â£5000 prize!'\n",
    "X = tfidf_vec_fit_loaded.transform([text])\n",
    "pred = spam_detect_model_loaded.predict(X)\n",
    "if pred[0]==0:\n",
    "    print('ham')\n",
    "else:\n",
    "    print('spam')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c16ea9e",
   "metadata": {},
   "source": [
    "# Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "676d63da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy = #(predicted correctly) / #(observation)\n",
    "#precision = #(predicted as spam correctly) / #(predicted as spam)\n",
    "#recall    = #(predicted as spam correctly) / #(actual spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "cbe46a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# another machine lerning algorithms\n",
    "# LogisticRegression\n",
    "# Support Vector Machine (SVM)\n",
    "# KNN\n",
    "# XGBClassifier Model\n",
    "#...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096773eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
